{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UupSt5hhWbYW"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import torch\n",
        "from torch.nn import (\n",
        "    BatchNorm1d,\n",
        "    Embedding,\n",
        "    Linear,\n",
        "    ModuleList,\n",
        "    ReLU,\n",
        "    Sequential,\n",
        ")\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import ZINC, LRGBDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_add_pool\n",
        "import inspect\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn import Dropout, Linear, Sequential\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.inits import reset\n",
        "from torch_geometric.nn.resolver import (\n",
        "    activation_resolver,\n",
        "    normalization_resolver,\n",
        ")\n",
        "from torch_geometric.typing import Adj\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "from mamba_ssm import Mamba\n",
        "from torch_geometric.utils import degree, sort_edge_index\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from scipy.sparse.csgraph import floyd_warshall\n",
        "import scipy.sparse.csgraph as csg\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "SPLIT = \"train\"\n",
        "N_SAMPLES_MAX = 12000\n",
        "K = 8\n",
        "SAVE_DIR = f\"./data/precomputed_dist_masks/zinc/split={SPLIT}_n={N_SAMPLES_MAX}_k={K}.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomZINCDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path,\n",
        "        precomputed_masks_path_train=None,\n",
        "        precomputed_masks_path_val=None,\n",
        "        split=\"train\",\n",
        "        transform=None,\n",
        "        n_samples_max=N_SAMPLES_MAX,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.tg_dataset = ZINC(path, split=split, transform=transform)\n",
        "        precomputed_masks_path = precomputed_masks_path_train if split == \"train\" else precomputed_masks_path_val\n",
        "        if precomputed_masks_path is not None:\n",
        "            with open(precomputed_masks_path, \"rb\") as f:\n",
        "                self.precomputed_masks = torch.load(f) # (M, 4) == (graph_idx, node1, node2, dist)\n",
        "        else: \n",
        "            self.precomputed_masks = None\n",
        "        \n",
        "        self.n_samples_max = n_samples_max\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= self.n_samples_max:\n",
        "            raise IndexError\n",
        "        g = self.tg_dataset[idx]\n",
        "        if self.precomputed_masks is not None:\n",
        "            g.dist_mask = self.precomputed_masks[self.precomputed_masks[:,0] == idx]\n",
        "        return g\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples_max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6mpBj0Rk9uRP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20}\n",
            "{1, 2, 3}\n",
            "Counter()\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "def floyd_warshall(adj_matrix, K):\n",
        "    shortest_paths = csg.floyd_warshall(adj_matrix, directed=False)\n",
        "    k_matrix = np.transpose((np.arange(K+1) == shortest_paths[...,None]).astype(int), (2, 0, 1))\n",
        "\n",
        "    return k_matrix \n",
        "\n",
        "train_dataset = CustomZINCDataset(path = \"/usr0/home/manhbaon/data/SeqForGraphs/datasets/zinc\",  split=SPLIT)\n",
        "\n",
        "max_num_modes = 0\n",
        "feature_values = set()\n",
        "edge_values = set()\n",
        "# counter of targets\n",
        "targets = Counter()\n",
        "for i, data in enumerate(train_dataset):\n",
        "    max_num_modes = max(max_num_modes, len(data.x))\n",
        "    feature_values.update(data.x.numpy().flatten())\n",
        "    edge_values.update(data.edge_attr.numpy().flatten())\n",
        "    for class_labels in data.y:\n",
        "        # Convert the tensor to a list of indices where the class is present\n",
        "        class_indices = torch.where(class_labels == 1)[0].tolist()\n",
        "        targets.update(class_indices)\n",
        "    \n",
        "\n",
        "    \n",
        "print(feature_values)\n",
        "print(edge_values)\n",
        "# print relative target counts\n",
        "print(targets)\n",
        "print({k: v / sum(targets.values()) for k, v in targets.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 1])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Precompute and save dist_masks\n",
        "dist_masks = []\n",
        "for i, data in enumerate(train_dataset):\n",
        "    adj_matrix = to_dense_adj(data.edge_index, max_num_nodes=max_num_modes).squeeze(0).numpy()\n",
        "    k_matrix = floyd_warshall(adj_matrix, K)\n",
        "    dist_masks.append( torch.tensor(k_matrix, dtype=torch.float32) )\n",
        "\n",
        "# Save each dist_mask to disk\n",
        "dist_mask = torch.stack(dist_masks, dim = 0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000, 9, 37, 37])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist_mask.shape #(N, K+1, num_nodes, num_nodes) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5678206, 4])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([5678206, 4])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compressed represenation\n",
        "compressed_dist_mask2 = []\n",
        "for k in range(K+1):\n",
        "    k_masks = torch.nonzero(dist_mask[:,k,...] == 1.0) #(n, node_1, node_2)\n",
        "    k_masks = torch.cat([k_masks, torch.tensor([K-k]).repeat( k_masks.shape[0],1)], dim=1) \n",
        "    compressed_dist_mask2.append( k_masks  )\n",
        "compressed_dist_mask2 = torch.cat(compressed_dist_mask2, dim=0)\n",
        "print(compressed_dist_mask2.shape) # (M,4) == (graph_id, node_1, node_2, k)\n",
        "\n",
        "compressed_dist_mask = torch.nonzero(dist_mask == 1.0) #(n, node_1, node_2, k)\n",
        "compressed_dist_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.all(torch.unique(compressed_dist_mask2) == torch.unique(compressed_dist_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# idxs = (compressed_dist_mask[:,:2] == torch.Tensor([0,0])).all(dim=1).nonzero()\n",
        "# compressed_dist_mask[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len((compressed_dist_mask[:,:2] == torch.Tensor([3,0])).all(dim=1).nonzero())==max_num_modes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create dir from fname\n",
        "os.makedirs(osp.dirname(SAVE_DIR), exist_ok=True)\n",
        "torch.save(compressed_dist_mask, SAVE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
